<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cesipy's Corner</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/water.css@2/out/water.css">
    <link rel="stylesheet" href="/styles.css">
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
    </script>
     <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <header>

    <img src="/assets/cesipis_corner_white_gb.png" alt="Cesipy's Corner Logo" class="logo-light" style="max-width: 350px; width: 100%;">
    <img src="/assets/cesipis_corner_black_bg.png" alt="Cesipy's Corner Logo" class="logo-dark" style="max-width: 350px; width: 100%;">
    <p>Thoughts, notes, and experiments.</p>
    <nav>
      <a href="/index.html">Home</a>
      <a href="/about.html">About me</a>
    </nav>
    <hr>
  </header>

  <main>
    <h1 id="torch-autograd">Torch autograd</h1>
    <p>This blogpost is my documented journey through autograd in torch.
    For the last two years I’ve been using pytorch, without properly
    understanding the mechanics of automatic differentiation. Of course
    I was aware of the mechanism of Backprop in general, as we
    thoroughly learned it in a Deep Learning course at university. There
    we studied it from a mathematical perspective and had to rehearse it
    until we could do it in our sleeps. But I fully understood how it
    was actually implemented in pytorch. And honestly, that was fine. If
    I would not have touched torch and pythons deep learning libraries
    without knowing every detail of its mechanisms, I would have never
    started. Torch can be overwhelming at first and so much is possible.
    Therefore Im a big proponent of using it hands on and learning it
    afterwards when you need it on the fly, a la Karpathy (insert link).
    “you only need to learn on demand”.</p>
    <h2 id="mathematical-perspective-of-backpropagation">Mathematical
    perspective of backpropagation</h2>
    <p>The general goal of Backpropagation is to calculate <span
    class="math inline">\(\frac{\partial L}{\partial w}\)</span>. This
    is, for every weight <span class="math inline">\(w \in
    \theta\)</span>, we want to calculate its derivative of the loss.
    This means intuitively, how much weight <span
    class="math inline">\(w_i\)</span> contributes to the current loss
    <span class="math inline">\(L\)</span>, to see how you can improve
    the network.</p>
    <p>The core idea is that this can be calculated using the chain
    rule, which comes in handy. To revisit the chain rule: <span
    class="math display">\[
        g(f(x))&#39; = g&#39;(f(x)) \cdot f&#39;(x)
    \]</span></p>
    <p>The objective for our statistical model <span
    class="math inline">\(f(x)\)</span> is to minimize the loss, eg.
    <span class="math display">\[
        \min_\theta L(y, f(x; \theta))
    \]</span></p>
    <p>for every single weight <span class="math inline">\(w \in
    \theta\)</span>. So ideally, the following holds: <span
    class="math inline">\(L(y, f(x;\theta))=0\)</span>.</p>
    <p>How to do that? deriving the loss in terms of <span
    class="math inline">\(w\)</span> and updating <span
    class="math inline">\(w\)</span> accordingly using gradient
    descent!</p>
    <p>therefore, we want to compute <span class="math display">\[
        \frac{\partial L}{\partial w} = \frac{\partial L}{\partial
    f}  \frac{\partial f}{\partial w}
    \]</span></p>
    <p>Suppose we use a simple neural network with only one layer with
    three weights. Therefore, the model can be formalized to: <span
    class="math display">\[
    f(x;\theta) =h(w_1 x_1 + w_2 x_2 + w_3 x_3 + b) = h(a)
    \]</span></p>
    <p>Note here, that the bias can be handled as an additional weight
    with constant input of 1, so we can ignore it for now. Here, <span
    class="math inline">\(h\)</span> is the activation function,
    e.g. ReLU or sigmoid. For this formalization, lets use the identity
    function, so <span class="math inline">\(h(a) = a\)</span>. In
    addition, we use <span class="math inline">\(L2\)</span> loss:</p>
    <p><span class="math display">\[
    L(x,y) = (x-y)^2
    \]</span></p>
    <p>To compute <span class="math inline">\(\frac{\partial L}{\partial
    w_1}\)</span>, we get the following: <span class="math display">\[
        \frac{\partial L}{\partial w_1} = \frac{\partial L}{\partial f}
    \cdot \frac{\partial f}{\partial a} \cdot \frac{\partial a}{\partial
    w_1}
    \]</span></p>
    <p>Now we can compute each part separately: - <span
    class="math inline">\(\frac{\partial a}{\partial w_1} = x_1\)</span>
    (simple derivative of linear function) - <span
    class="math inline">\(\frac{\partial f}{\partial a} = h&#39;(a) =
    1\)</span> (derivative of identity function) - <span
    class="math inline">\(\frac{\partial L}{\partial f} = 2(f(x) -
    y)\)</span> (derivative of L2 loss)</p>
    <p>We simply stick this together by mutliplying it:</p>
    <p><span class="math display">\[
        \frac{\partial L}{\partial w_1} = 2(f(x) - y) \cdot 1 \cdot x_1
    = 2(f(x) - y) x_1
    \]</span></p>
    <p>Of course in real neural network we use different activation
    functions. For every activation function however it is possible to
    calculate its derivative beforehand. The same holds for different
    loss function. It is easy to calculate the derivative of the loss
    function beforehand.</p>
    <p>For deeper networks with multiple layers, the same principle
    applies. The chain rule is applied multiple times, where each layer
    contributes its own derivative.</p>
    <p>Lets say we have a two layer network: <span
    class="math display">\[
    f(x;\theta) = h_2(w_2 h_1(w_1 x + b_1) + b_2)
    \]</span> To compute <span class="math inline">\(\frac{\partial
    L}{\partial w_1}\)</span>, we get: <span class="math display">\[
        \frac{\partial L}{\partial w_1} = \frac{\partial L}{\partial f}
    \cdot \frac{\partial f}{\partial h_2} \cdot \frac{\partial
    h_2}{\partial a_2} \cdot \frac{\partial a_2}{\partial h_1} \cdot
    \frac{\partial h_1}{\partial a_1} \cdot \frac{\partial a_1}{\partial
    w_1}
    \]</span> …</p>
    <h2 id="simple-examples">Simple examples</h2>
    <p>So how does torch autograd work in practice? Let’s see in a
    simple example for two tensors, <span class="math inline">\(a = 4,
    b=3\)</span>.</p>
    <div class="sourceCode" id="cb1"><pre
    class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#simple grads:</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.tensor(<span class="dv">4</span>, dtype<span class="op">=</span>torch.float32, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.tensor(<span class="dv">3</span>, dtype<span class="op">=</span>torch.float32, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#compute gradients for leaf nodes a, b</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>c.backward()</span></code></pre></div>
    <p>what do we expect to see when computing <span
    class="math inline">\(\frac{c}{a}\)</span>? By simple calculus rules
    we expect <span class="math inline">\(\frac{c}{a} = b = 3\)</span>.
    Let’s see the output:</p>
    <div class="sourceCode" id="cb2"><pre
    class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">a.grad:</span> 3.0</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">b.grad:</span> 4.0</span></code></pre></div>
    <p>Nice!</p>
    <p>Note that the gradients are accumulated.</p>
    <div class="sourceCode" id="cb3"><pre
    class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#compute gradients for leaf nodes a, b</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>c.backward()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;a.grad: </span><span class="sc">{</span>a<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;b.grad: </span><span class="sc">{</span>b<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>c.backward()</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;a.grad after second backward: </span><span class="sc">{</span>a<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">&quot;</span>)  <span class="co"># prints 6.0</span></span></code></pre></div>
    <p>This is useful when doing gradient accumulation when you want to
    simulate larger batch sizes than your hardware allows.</p>
    <h2 id="neural-network-example">Neural network example</h2>
    <p>in order to generalize the example to neural network, consider
    the following example. Here we artificially construct a dataset with
    two inputs <span class="math inline">\(x_1, x_2\)</span> a scalar
    output <span class="math inline">\(y=x_1 + 0.1x_2^2\)</span></p>
    <p>We want to learn a simple linear layer <span
    class="math inline">\(\vec w = w_1, w_2\)</span> to learn the
    data.</p>
    <div class="sourceCode" id="cb4"><pre
    class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>dps <span class="op">=</span> [     <span class="co"># generates the dataset</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        torch.tensor((x1, x2), dtype<span class="op">=</span>torch.float32),</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        torch.tensor(x1<span class="op">+</span> <span class="fl">.02</span><span class="op">*</span>x2<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x1 <span class="kw">in</span> <span class="bu">range</span>(num_samples) <span class="cf">for</span> x2 <span class="kw">in</span> <span class="bu">range</span>(num_samples)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>]       <span class="co">#len(dps) = num_samples^2</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor([<span class="fl">0.0213</span>, <span class="fl">0.00124</span>], dtype<span class="op">=</span>torch.float32, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> dps[<span class="dv">10</span>][<span class="dv">0</span>]<span class="op">;</span> y <span class="op">=</span> dps[<span class="dv">10</span>][<span class="dv">1</span>]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> w <span class="op">@</span> x</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> (y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>   <span class="co">#simple least squares</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>loss.backward()</span></code></pre></div>
    <p>The output shows:
    <code>w.grad: tensor([-57.8978, -34.7387])</code> for
    <code>x=tensor([5., 3.]) tensor(52)</code>. with a loss of
    <code>2692.5</code>.
    <code>input tensor([5., 3.]), y: 5.900000095367432, y_hat: 0.11022000014781952, loss: 33.52155303955078</code>
    Ok now we know the loss, i.e the error and can calculate how to
    change the weights to reduce the loss.</p>
    <p>So theoretically, what do we expect? The following is the
    analytical solution for the derivative of <span
    class="math inline">\(w_1\)</span> <span class="math display">\[
    \frac{\partial L}{\partial w_1} = \frac{(w_1 x1 + w_2x2 -
    y)^2}{\partial w_1} = 2 (w_1 x_1 + w_2x_2 - y) x_1
    \\
    \Rightarrow 2(0.0213 \cdot 5 + 0.00124\cdot 3 - 5.9) \cdot 5 =
    -57.89.
    \]</span> As we can see, our calculated gradient is correct!</p>
    <p>What happens under the hood? The autograd engine builds a
    computational graph dynamically, where each tensor operation creates
    a new node in the graph. Each node keeps track of the operation that
    created it and its parent nodes. When we call
    <code>backward()</code>, PyTorch traverses this graph in reverse
    order, applying the chain rule to compute gradients for each tensor
    that has <code>requires_grad=True</code>.</p>
    <p>using the gradient descent optimization, we can update the weight
    and rerun and see how it works:</p>
    <div class="sourceCode" id="cb5"><pre
    class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> w <span class="op">-</span> lr <span class="op">*</span> w.grad</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># recalculate:</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> dps[<span class="dv">53</span>][<span class="dv">0</span>]<span class="op">;</span> y <span class="op">=</span> dps[<span class="dv">53</span>][<span class="dv">1</span>]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> w <span class="op">@</span> x</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> (y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;after one gradient step: input </span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">, y: </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">, y_hat: </span><span class="sc">{</span>y_hat<span class="sc">}</span><span class="ss">, loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
    <p>As you can see below, this significantly increases our
    prediction!</p>
    <div class="sourceCode" id="cb6"><pre
    class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">input</span> tensor<span class="er">(</span><span class="ex">[5.,</span> 3.]<span class="kw">)</span><span class="ex">,</span> y: 52, y_hat: 0.11022000014781952, loss: 2692.549072265625</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="ex">after</span> one gradient step: input tensor<span class="er">(</span><span class="ex">[5.,</span> 3.]<span class="kw">)</span><span class="ex">,</span> y: 52, y_hat: 17.75274658203125, loss: 1172.8743896484375</span></code></pre></div>
    <p>Of course, we don’t want the model to overfit and <em>only learn
    to fit</em> one sample. For this above case, we update the weights
    only based on one sample. To test the loss for the whole dataset
    even if only one sample is optimized the following plot shows:</p>
    <div class="sourceCode" id="cb7"><pre
    class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># len(dps) = 64</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> <span class="dv">53</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> dps[sample][<span class="dv">0</span>]<span class="op">;</span> y <span class="op">=</span> dps[sample][<span class="dv">1</span>]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    avg_loss <span class="op">=</span> evaluate_over_dataset(dps, w)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> w <span class="op">@</span> x</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> (y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>   <span class="co">#simple least squares</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        w <span class="op">-=</span> lr <span class="op">*</span> w.grad</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        w.grad.zero_()</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;epochs </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, avg_loss: </span><span class="sc">{</span>avg_loss<span class="sc">}</span><span class="ss">, individual_loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
    <p>The plot below shows a cool thing:
    <img src="/posts/res/2025-11-13-13-27-49.png" width=300 > We are not
    overfitting, but really decreasing the overall loss. This indicates
    that one sample here is already helping to generalize, but has only
    limited information for the whole dataset. individual loss decreases
    and therefore also decreases overall loss. but when this is fitted,
    there is no more information to gain from this sample and the
    overall loss stagnates. Here the avg loss is aroung 26, while the
    individual loss is at 2.6</p>
    <p>In the next step the gradient is accumulated for the whole
    dataset and then updated using standard gradient descent.</p>
    <div class="sourceCode" id="cb8"><pre
    class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a> <span class="kw">def</span> forward_step(x, y, w):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>        y_hat <span class="op">=</span> w <span class="op">@</span> x</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> (y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>   <span class="co">#simple least squares</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_over_dataset(dps, w):</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x, y <span class="kw">in</span> dps:</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> forward_step(x, y, w).item()</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_loss <span class="op">/</span> <span class="bu">len</span>(dps)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_over_dataset(dps, w):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x, y <span class="kw">in</span> dps:</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> forward_step(x, y, w)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        w <span class="op">-=</span> lr <span class="op">*</span> w.grad</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        w.grad.zero_()</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    avg_loss <span class="op">=</span> evaluate_over_dataset(dps, w)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    train_over_dataset(dps, w)</span></code></pre></div>
    <p>Here all the operations are accumulated to a large computational
    graph. Calling the final <code>loss.backward()</code>, the gradient
    is calculated for all operations. This converges to a lower avg loss
    of around 5 after 25 epochs.
    <img src="/posts/res/2025-11-25-11-05-52.png" width=300 ></p>
    <p>of course we are not able to completely fit the data with only
    two weights, as the function includes a quadratic term.</p>
    <p>This really simple networks allows for better understanding of
    the autograd mechanism. For only one sample, the computation graph
    looks like this:
    <img src="/posts/res/2025-11-25-11-42-47.png" width=250 > So let’s
    break it down. The following code is used to collect the gradients
    for the graph, where the graph in the plot are added directly to the
    code:</p>
    <div class="sourceCode" id="cb9"><pre
    class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_step(x, y, w):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>        y_hat <span class="op">=</span> w <span class="op">@</span> x       <span class="co"># DotBackward0</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> (y_hat <span class="op">-</span> y)  <span class="co"># SubBackward0</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss<span class="op">**</span><span class="dv">2</span>      <span class="co"># PowBackward0</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> evaluate_over_dataset(dps, w):</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> x, y <span class="kw">in</span> dps:</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> forward_step(x, y, w)   <span class="co"># AddBackward0</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> total_loss  <span class="op">/</span> <span class="bu">len</span>(dps) <span class="co"># DivBackward0</span></span></code></pre></div>
    <p>This is pretty simple! Note that <code>PowBackward0</code> has an
    exponent of 2 and <code>DotBackward0</code> operates <span
    class="math inline">\(w\cdot 2\)</span> because of the chain rule.
    This is formalized in the equation above.</p>
    <p>What happens if we do this with 4 samples instead of just one? We
    expect to have the same operations, but the respective samples are
    added before division.</p>
    <p><img src="/posts/res/2025-11-25-11-49-45.png" width=300 > and
    thats exactly happening!</p>
    <p>So the computational graph for each sample looks the same, but
    before performing the avg calculation of the loss, all individual
    losses are summed up using <code>AddBackward</code> nodes.</p>
    <p>Now with even more samples! (n=36)
    <img src="/posts/res/2025-11-25-11-51-24.png" width=300 > But this
    gets very hard to look at. However, the idea is really simple:
    pytroch builds a computational graph for all operations done in the
    neural network. When calling <code>loss.backward()</code>, the graph
    is traversed in reverse order and the chain rule is applied to
    calculate the gradients.</p>
    <p>This visualization shows how the gradient descent works in the
    loss landscape:
    <img src="/posts/res/2025-11-13-13-45-57.png" width=300 ></p>
  </main>

  <footer>
    <hr>
    <p>© 2025 Cedric Sillaber</p>
  </footer>
</body>
</html>