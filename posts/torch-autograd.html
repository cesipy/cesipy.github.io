<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cesipy's Corner</title>
    <link rel="stylesheet" href="/styles.css">
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <button class="theme-toggle" id="theme-toggle" aria-label="Toggle dark mode">☾</button>

  <header>
    <img src="/assets/cesipis_corner_black_text.png" alt="Cesipy's Corner Logo" class="logo-light">
    <img src="/assets/cesipis_corner_white_text.png" alt="Cesipy's Corner Logo" class="logo-dark">
    <p>thoughts, notes, and experiments.</p>
    <nav>
      <a href="/index.html">home</a>
      <a href="/about.html">about</a>
      <a href="/archive.html">archive</a>
    </nav>
    <hr>
  </header>

  <main>
    <article>
      <h1 id="torch-autograd">torch autograd</h1>
      <p>this blogpost is my documented journey through autograd in
      torch. for the last two years i’ve been using pytorch, without
      properly understanding the mechanics of automatic differentiation.
      of course i was aware of the mechanism of backprop in general, as
      we thoroughly learned it in a deep learning course at university.
      there we studied it from a mathematical perspective and had to
      rehearse it until we could do it in our sleep. but i never fully
      understood how it was actually implemented in pytorch. and
      honestly, that was fine. if i would not have touched torch and
      python’s deep learning libraries without knowing every detail of
      its mechanisms, i would have never started. torch can be
      overwhelming at first and so much is possible. therefore i’m a big
      proponent of using it hands on and learning it afterwards when you
      need it on the fly, à la karpathy (<a
      href="https://x.com/karpathy/status/1325154823856033793?lang=en">this
      tweet</a>). “you only need to learn on demand”.</p>
      <h2 id="mathematical-perspective-of-backpropagation">mathematical
      perspective of backpropagation</h2>
      <p>the general goal of backpropagation is to calculate <span
      class="math inline">\(\frac{\partial L}{\partial w}\)</span>. this
      is, for every weight <span class="math inline">\(w \in
      \theta\)</span>, we want to calculate its derivative of the loss.
      this means intuitively, how much weight <span
      class="math inline">\(w_i\)</span> contributes to the current loss
      <span class="math inline">\(L\)</span>, to see how you can improve
      the network.</p>
      <p>the core idea is that this can be calculated using the chain
      rule, which comes in handy. to revisit the chain rule:</p>
      <p><span class="math display">\[
          g(f(x))&#39; = g&#39;(f(x)) \cdot f&#39;(x)
      \]</span></p>
      <p>the objective for our statistical model <span
      class="math inline">\(f(x)\)</span> is to minimize the loss, eg.
      <span class="math display">\[
          \min_\theta L(y, f(x; \theta))
      \]</span></p>
      <p>for every single weight <span class="math inline">\(w \in
      \theta\)</span>. so ideally, the following holds: <span
      class="math inline">\(L(y, f(x;\theta))=0\)</span>.</p>
      <p>how to do that? deriving the loss in terms of <span
      class="math inline">\(w\)</span> and updating <span
      class="math inline">\(w\)</span> accordingly using gradient
      descent!</p>
      <p>therefore, we want to compute <span class="math display">\[
          \frac{\partial L}{\partial w} = \frac{\partial L}{\partial
      f}  \frac{\partial f}{\partial w}
      \]</span></p>
      <p>suppose we use a simple neural network with only one layer with
      three weights. therefore, the model can be formalized to: <span
      class="math display">\[
      f(x;\theta) =h(w_1 x_1 + w_2 x_2 + w_3 x_3 + b) = h(a)
      \]</span></p>
      <p>note here, that the bias can be handled as an additional weight
      with constant input of 1, so we can ignore it for now. here, <span
      class="math inline">\(h\)</span> is the activation function,
      e.g. ReLU or sigmoid. for this formalization, let’s use the
      identity function, so <span class="math inline">\(h(a) =
      a\)</span>. in addition, we use <span
      class="math inline">\(L2\)</span> loss:</p>
      <p><span class="math display">\[
      L(x,y) = (x-y)^2
      \]</span></p>
      <p>to compute <span class="math inline">\(\frac{\partial
      L}{\partial w_1}\)</span>, we get the following: <span
      class="math display">\[
          \frac{\partial L}{\partial w_1} = \frac{\partial L}{\partial
      f} \cdot \frac{\partial f}{\partial a} \cdot \frac{\partial
      a}{\partial w_1}
      \]</span></p>
      <p>now we can compute each part separately: - <span
      class="math inline">\(\frac{\partial a}{\partial w_1} =
      x_1\)</span> (simple derivative of linear function) - <span
      class="math inline">\(\frac{\partial f}{\partial a} = h&#39;(a) =
      1\)</span> (derivative of identity function) - <span
      class="math inline">\(\frac{\partial L}{\partial f} = 2(f(x) -
      y)\)</span> (derivative of L2 loss)</p>
      <p>we simply stick this together by multiplying it:</p>
      <p><span class="math display">\[
          \frac{\partial L}{\partial w_1} = 2(f(x) - y) \cdot 1 \cdot
      x_1 = 2(f(x) - y) x_1
      \]</span></p>
      <p>of course in real neural networks we use different activation
      functions. for every activation function however it is possible to
      calculate its derivative beforehand. the same holds for different
      loss functions. it is easy to calculate the derivative of the loss
      function beforehand.</p>
      <p>for deeper networks with multiple layers, the same principle
      applies. the chain rule is applied multiple times, where each
      layer contributes its own derivative.</p>
      <p>let’s say we have a two layer network: <span
      class="math display">\[
      f(x;\theta) = h_2(w_2 h_1(w_1 x + b_1) + b_2)
      \]</span> to compute <span class="math inline">\(\frac{\partial
      L}{\partial w_1}\)</span>, we get: <span class="math display">\[
          \frac{\partial L}{\partial w_1} = \frac{\partial L}{\partial
      f} \cdot \frac{\partial f}{\partial h_2} \cdot \frac{\partial
      h_2}{\partial a_2} \cdot \frac{\partial a_2}{\partial h_1} \cdot
      \frac{\partial h_1}{\partial a_1} \cdot \frac{\partial
      a_1}{\partial w_1}
      \]</span> …</p>
      <h2 id="simple-examples">simple examples</h2>
      <p>so how does torch autograd work in practice? let’s see in a
      simple example for two tensors, <span class="math inline">\(a = 4,
      b=3\)</span>.</p>
      <div class="sourceCode" id="cb1"><pre
      class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#simple grads:</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.tensor(<span class="dv">4</span>, dtype<span class="op">=</span>torch.float32, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.tensor(<span class="dv">3</span>, dtype<span class="op">=</span>torch.float32, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#compute gradients for leaf nodes a, b</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>c.backward()</span></code></pre></div>
      <p>what do we expect to see when computing <span
      class="math inline">\(\frac{\partial c}{\partial a}\)</span>? by
      simple calculus rules we expect <span
      class="math inline">\(\frac{\partial c}{\partial a} = b =
      3\)</span>. let’s see the output:</p>
      <div class="sourceCode" id="cb2"><pre
      class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">a.grad:</span> 3.0</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">b.grad:</span> 4.0</span></code></pre></div>
      <p>nice!</p>
      <p>note that the gradients are accumulated.</p>
      <div class="sourceCode" id="cb3"><pre
      class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#compute gradients for leaf nodes a, b</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>c.backward()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;a.grad: </span><span class="sc">{</span>a<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;b.grad: </span><span class="sc">{</span>b<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>c.backward()</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;a.grad after second backward: </span><span class="sc">{</span>a<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">&quot;</span>)  <span class="co"># prints 6.0</span></span></code></pre></div>
      <p>this is useful when doing gradient accumulation when you want
      to simulate larger batch sizes than your hardware allows.</p>
      <h2 id="neural-network-example">neural network example</h2>
      <p>in order to generalize the example to neural networks, consider
      the following example. here we artificially construct a dataset
      with two inputs <span class="math inline">\(x_1, x_2\)</span> and
      a scalar output <span class="math inline">\(y=x_1 +
      0.1x_2^2\)</span>.</p>
      <p>we want to learn a simple linear layer <span
      class="math inline">\(\vec w = w_1, w_2\)</span> to learn the
      data.</p>
      <div class="sourceCode" id="cb4"><pre
      class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>dps <span class="op">=</span> [     <span class="co"># generates the dataset</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        torch.tensor((x1, x2), dtype<span class="op">=</span>torch.float32),</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        torch.tensor(x1 <span class="op">+</span> <span class="fl">.1</span><span class="op">*</span>x2<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x1 <span class="kw">in</span> <span class="bu">range</span>(num_samples) <span class="cf">for</span> x2 <span class="kw">in</span> <span class="bu">range</span>(num_samples)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>]       <span class="co">#len(dps) = num_samples^2</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor([<span class="fl">0.0213</span>, <span class="fl">0.00124</span>], dtype<span class="op">=</span>torch.float32, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> dps[<span class="dv">10</span>][<span class="dv">0</span>]<span class="op">;</span> y <span class="op">=</span> dps[<span class="dv">10</span>][<span class="dv">1</span>]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> w <span class="op">@</span> x</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> (y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>   <span class="co">#simple least squares</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>loss.backward()</span></code></pre></div>
      <p>the output shows:
      <code>w.grad: tensor([-57.8978, -34.7387])</code> for
      <code>x=tensor([5., 3.])</code>, <code>y=5.9</code>, with a loss
      of <code>33.52</code>.</p>
      <p>now we know the loss and can calculate how to update the
      weights to reduce it.</p>
      <p>so theoretically, what do we expect? the following is the
      analytical solution for the derivative of <span
      class="math inline">\(w_1\)</span>: <span class="math display">\[
      \frac{\partial L}{\partial w_1} = \frac{\partial (w_1 x_1 + w_2
      x_2 - y)^2}{\partial w_1} = 2 (w_1 x_1 + w_2 x_2 - y) x_1
      \\
      \Rightarrow 2(0.0213 \cdot 5 + 0.00124\cdot 3 - 5.9) \cdot 5 =
      -57.89
      \]</span> as we can see, our calculated gradient is correct!</p>
      <p>what happens under the hood? the autograd engine builds a
      computational graph dynamically, where each tensor operation
      creates a new node in the graph. each node keeps track of the
      operation that created it and its parent nodes. when we call
      <code>backward()</code>, pytorch traverses this graph in reverse
      order, applying the chain rule to compute gradients for each
      tensor that has <code>requires_grad=True</code>.</p>
      <p>using gradient descent optimization, we can update the weight
      and rerun and see how it works:</p>
      <div class="sourceCode" id="cb5"><pre
      class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> w <span class="op">-</span> lr <span class="op">*</span> w.grad</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># recalculate:</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> dps[<span class="dv">53</span>][<span class="dv">0</span>]<span class="op">;</span> y <span class="op">=</span> dps[<span class="dv">53</span>][<span class="dv">1</span>]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> w <span class="op">@</span> x</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> (y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;after one gradient step: input </span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">, y: </span><span class="sc">{</span>y<span class="sc">}</span><span class="ss">, y_hat: </span><span class="sc">{</span>y_hat<span class="sc">}</span><span class="ss">, loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
      <p>as you can see below, this significantly improves our
      prediction!</p>
      <div class="sourceCode" id="cb6"><pre
      class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">input</span> tensor<span class="er">(</span><span class="ex">[5.,</span> 3.]<span class="kw">)</span><span class="ex">,</span> y: 5.9, y_hat: 0.11022000014781952, loss: 33.52155303955078</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="ex">after</span> one gradient step: input tensor<span class="er">(</span><span class="ex">[5.,</span> 3.]<span class="kw">)</span><span class="ex">,</span> y: 5.9, y_hat: 2.89, loss: 9.06</span></code></pre></div>
      <p>of course, we don’t want the model to overfit and <em>only
      learn to fit</em> one sample. for this above case, we update the
      weights only based on one sample. to test the loss for the whole
      dataset even if only one sample is optimized, the following plot
      shows:</p>
      <div class="sourceCode" id="cb7"><pre
      class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># len(dps) = 64</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> <span class="dv">53</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> dps[sample][<span class="dv">0</span>]<span class="op">;</span> y <span class="op">=</span> dps[sample][<span class="dv">1</span>]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    avg_loss <span class="op">=</span> evaluate_over_dataset(dps, w)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> w <span class="op">@</span> x</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> (y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>   <span class="co">#simple least squares</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        w <span class="op">-=</span> lr <span class="op">*</span> w.grad</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        w.grad.zero_()</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;epochs </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, avg_loss: </span><span class="sc">{</span>avg_loss<span class="sc">}</span><span class="ss">, individual_loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
      <p>the plot below shows a cool thing:</p>
      <figure>
      <img src="/posts/res/2025-11-13-13-27-49.png" width=300 >
      </figure>
      <p>we are not overfitting, but really decreasing the overall loss.
      one sample carries enough signal to reduce overall loss, but only
      so much—once it’s fit, there’s no more information to extract from
      it, and the overall loss stagnates. here the avg loss is around
      26, while the individual loss is at 2.6.</p>
      <p>in the next step the gradient is accumulated for the whole
      dataset and then updated using standard gradient descent.</p>
      <div class="sourceCode" id="cb8"><pre
      class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_step(x, y, w):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> w <span class="op">@</span> x</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> (y_hat <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>   <span class="co">#simple least squares</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_over_dataset(dps, w):</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x, y <span class="kw">in</span> dps:</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> forward_step(x, y, w).item()</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_loss <span class="op">/</span> <span class="bu">len</span>(dps)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_over_dataset(dps, w):</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x, y <span class="kw">in</span> dps:</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> forward_step(x, y, w)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        w <span class="op">-=</span> lr <span class="op">*</span> w.grad</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        w.grad.zero_()</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    avg_loss <span class="op">=</span> evaluate_over_dataset(dps, w)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    train_over_dataset(dps, w)</span></code></pre></div>
      here all the operations are accumulated to a large computational
      graph. calling the final <code>loss.backward()</code>, the
      gradient is calculated for all operations. this converges to a
      lower avg loss of around 5 after 25 epochs.
      <figure>
      <img src="/posts/res/2025-11-25-11-05-52.png" width=300 >
      </figure>
      <p>of course we are not able to completely fit the data with only
      two weights, as the function includes a quadratic term.</p>
      <p>this really simple network allows for better understanding of
      the autograd mechanism. for only one sample, the computation graph
      looks like this:</p>
      <figure>
      <img src="/posts/res/2025-11-25-11-42-47.png" width=250 >
      </figure>
      <p>so let’s break it down. the following code is used to collect
      the gradients for the graph, where the graph nodes are added
      directly to the code:</p>
      <div class="sourceCode" id="cb9"><pre
      class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward_step(x, y, w):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> w <span class="op">@</span> x       <span class="co"># DotBackward0</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> (y_hat <span class="op">-</span> y)  <span class="co"># SubBackward0</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss<span class="op">**</span><span class="dv">2</span>      <span class="co"># PowBackward0</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_over_dataset(dps, w):</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x, y <span class="kw">in</span> dps:</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">+=</span> forward_step(x, y, w)   <span class="co"># AddBackward0</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_loss <span class="op">/</span> <span class="bu">len</span>(dps) <span class="co"># DivBackward0</span></span></code></pre></div>
      <p>this is pretty simple! note that <code>PowBackward0</code> has
      an exponent of 2 and <code>DotBackward0</code> operates on <span
      class="math inline">\(w \cdot x\)</span> because of the chain
      rule. this is formalized in the equation above.</p>
      <p>what happens if we do this with 4 samples instead of just one?
      we expect to have the same operations, but the respective samples
      are added before division.</p>
      <figure>
      <img src="/posts/res/2025-11-25-11-49-45.png" width=300 >
      </figure>
      <p>and that’s exactly what’s happening!</p>
      <p>so the computational graph for each sample looks the same, but
      before performing the avg calculation of the loss, all individual
      losses are summed up using <code>AddBackward</code> nodes.</p>
      <p>now with even more samples! (n=36)</p>
      <figure>
      <img src="/posts/res/2025-11-25-11-51-24.png" width=300 >
      </figure>
      <p>but this gets very hard to look at. however, the idea is really
      simple: pytorch builds a computational graph for all operations
      done in the neural network. when calling
      <code>loss.backward()</code>, the graph is traversed in reverse
      order and the chain rule is applied to calculate the
      gradients.</p>
      <p>this visualization shows how gradient descent works in the loss
      landscape:</p>
      <figure>
      <img src="/posts/res/2025-11-13-13-45-57.png" width=300 >
      </figure>
    </article>
  </main>

  <footer>
    <p>© 2025 Cedric Sillaber</p>
  </footer>

  <script>
    // Dark mode toggle
    const themeToggle = document.getElementById('theme-toggle');
    const body = document.body;

    // Check for saved theme preference or default to system preference
    const currentTheme = localStorage.getItem('theme');
    if (currentTheme) {
      body.classList.add(currentTheme);
      themeToggle.textContent = currentTheme === 'dark-mode' ? '☀' : '☾';
    }

    themeToggle.addEventListener('click', () => {
      if (body.classList.contains('dark-mode')) {
        body.classList.remove('dark-mode');
        body.classList.add('light-mode');
        themeToggle.textContent = '☾';
        localStorage.setItem('theme', 'light-mode');
      } else {
        body.classList.remove('light-mode');
        body.classList.add('dark-mode');
        themeToggle.textContent = '☀';
        localStorage.setItem('theme', 'dark-mode');
      }
    });
  </script>

  <!-- Cloudflare Web Analytics -->
  <script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "4607e4d2628345e4b4735caaa83aba09"}'></script>
  <!-- End Cloudflare Web Analytics -->
</body>
</html>